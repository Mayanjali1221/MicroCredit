{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b9d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Reading data \n",
    "df=pd.read_csv('Data file.csv')\n",
    "df.head()\n",
    "\n",
    "df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "df.head()\n",
    "\n",
    "#let's dive into depth \n",
    "df.info()\n",
    "\n",
    "# let's check null values \n",
    "df.isnull().sum()\n",
    "\n",
    "print(\"shape of data set is \",df.shape)\n",
    "\n",
    "unique = df.nunique()\n",
    "unique = unique[unique.values == 1]\n",
    "\n",
    "df.drop(labels = list(unique.index), axis =1, inplace=True)\n",
    "print(\"So now we are left with\",df.shape ,\"rows & columns.\")\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.describe().transpose()\n",
    "\n",
    "#Here we check the summary of object and datetime columns\n",
    "df.describe(include=['object','datetime']).transpose()\n",
    "\n",
    "df1=df.copy()\n",
    "\n",
    "#Deleting the duplicates entry in msidn column\n",
    "df = df.drop_duplicates(subset = 'msisdn',keep='first')\n",
    "df.shape\n",
    "\n",
    "#Printing the object datatypes and their unique values.\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtypes == object:\n",
    "        print(str(column) + ' : ' + str(df[column].unique()))\n",
    "        print('**********************************************************************************************************')\n",
    "        print('\\n')\n",
    "        \n",
    "#Printing the float datatype columns and number of unique values in the particular columns.\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtype==np.number:\n",
    "        print(str(column) + ' : ' + str(df[column].nunique()))\n",
    "        print(df[column].nunique())\n",
    "        print('//////*******************************************************************************///////')\n",
    "        \n",
    "#Checking the number of number of defaulter and non defaulter customers.\n",
    "df['label'].value_counts()\n",
    "\n",
    "#Checking the defaulter customers percentage wise.\n",
    "df['label'].value_counts(normalize=True) *100\n",
    "\n",
    "#check cor-relation\n",
    "df_cor = df.corr()\n",
    "df_cor\n",
    "\n",
    "#Dropping the columns which is highly correlated with each other do avoid multicolinearity problem.\n",
    "df.drop(columns=['daily_decr30','rental30','amnt_loans30','medianamnt_loans30'],axis=1, inplace = True)\n",
    "\n",
    "#Now checking the shape\n",
    "print(df.shape)\n",
    "#Checking the unique value in pdate column.\n",
    "df['pdate'].nunique()\n",
    "\n",
    "#Making the new column Day, Month and year from pdate column\n",
    "df['pDay']=pd.to_datetime(df['pdate'],format='%Y/%m/%d').dt.day\n",
    "df['pMonth']=pd.to_datetime(df['pdate'],format='%Y/%m/%d').dt.month\n",
    "df['pYear']=pd.to_datetime(df['pdate'],format='%Y/%m/%d').dt.year\n",
    "\n",
    "df.head()\n",
    "\n",
    "#Checking the number of months \n",
    "df['pMonth'].unique()\n",
    "\n",
    "#After fetching the data from pdate column now we are going to drop it because it has not any significant role.\n",
    "df.drop(columns=['pdate'],axis=1, inplace = True)\n",
    "\n",
    "#Seprate the categorical columns and Numerical columns\n",
    "cat_df,num_df=[],[]\n",
    "\n",
    "for i in df.columns:\n",
    "    if df[i].dtype==object:\n",
    "        cat_df.append(i)\n",
    "    elif (df[i].dtypes=='int64') | (df[i].dtypes=='float64') | (df[i].dtypes=='int32'):\n",
    "        num_df.append(i)\n",
    "    else: continue\n",
    "        \n",
    "print('>>> Total Number of Feature::', df.shape[1])\n",
    "print('>>> Number of categorical features::', len(cat_df))\n",
    "print('>>> Number of Numerical Feature::', len(num_df))\n",
    "\n",
    "#Checking the correlation with target variable\n",
    "plt.figure(figsize=(16,8))\n",
    "df.drop('label', axis=1).corrwith(df['label']).plot(kind='bar',grid=True)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"Correlation with target Variable that is label column\",fontsize=25)\n",
    "\n",
    "#Checking the number of Fraud cases.\n",
    "sns.countplot(x='label', data=df, palette='magma')\n",
    "plt.title('No of defaulter/Non-defaulter Case',fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "#Plotting the Histogram\n",
    "df.hist(figsize=(20,20),color='r')\n",
    "plt.show()\n",
    "\n",
    "#Customer label according to Date\n",
    "plt.figure(figsize=(20,8))\n",
    "sns.countplot(x=\"pDay\", hue='label', data=df, palette='autumn_r')\n",
    "plt.title(\"Customers label according to Date\", fontsize=25)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Counting of Customers')\n",
    "plt.show()\n",
    "\n",
    "#Customer label according to Month\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x=\"pMonth\", hue='label', data=df, palette='cool')\n",
    "plt.title(\"Customers label according to month\", fontsize=25)\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Counting of Customers')\n",
    "plt.show()\n",
    "\n",
    "#checking skewness\n",
    "\n",
    "for col in df.describe().columns:\n",
    "    sns.distplot(df[col],color='r')\n",
    "    plt.show()\n",
    "    \n",
    "df.skew()\n",
    "\n",
    "#Treating Skewness via square root method.\n",
    "df.skew()\n",
    "for col in df.skew().index:\n",
    "    if col in df.describe().columns:\n",
    "        if df[col].skew()>0.55:\n",
    "            df[col]=np.sqrt(df[col])\n",
    "            \n",
    "df.skew()\n",
    "\n",
    "#plotting outliers\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize = (18, 10))\n",
    "sns.boxplot(ax=ax1, x = 'label', y = 'last_rech_date_ma', hue = 'label', data = df)\n",
    "sns.boxplot(ax=ax2, x = 'label', y = 'last_rech_date_da', hue = 'label', data = df)\n",
    "sns.boxplot(ax=ax3, x = 'label', y = 'cnt_da_rech30', hue = 'label', data = df)\n",
    "sns.boxplot(ax=ax4, x = 'label', y = 'fr_da_rech30', hue = 'label', data = df)\n",
    "\n",
    "#Creating a copy of our dataset\n",
    "df2=df1.copy()\n",
    "#Dropping the object columns\n",
    "df1.drop(columns=['msisdn','pdate'],axis=1,inplace=True)\n",
    "\n",
    "df1.columns\n",
    "\n",
    "from scipy.stats import zscore\n",
    "z=np.abs(zscore(df1))\n",
    "z\n",
    "\n",
    "threshold=3\n",
    "print(np.where(z>3))\n",
    "\n",
    "df1_new=df1[(z<3).all(axis=1)]\n",
    "\n",
    "#Checking the shape\n",
    "print(df1.shape,'\\t\\t',df1_new.shape)\n",
    "\n",
    "#Converting the categorical data into numeric variables\n",
    "# Transform Non numeric columns into Numeric columns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtype==np.number:\n",
    "        continue\n",
    "    df[column]=le.fit_transform(df[column])\n",
    "    \n",
    "df.head()\n",
    "\n",
    "#feature importance\n",
    "\n",
    "#Splitting the data into x and y\n",
    "x = df.drop(['label'], axis=1)\n",
    "\n",
    "y = df['label']\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(max_depth=3)\n",
    "dt.fit(x, y)\n",
    "\n",
    "dt_features = pd.DataFrame(dt.feature_importances_, index=x.columns, columns=['feat_importance'])\n",
    "dt_features.sort_values('feat_importance').tail(10).plot.barh()\n",
    "plt.show()\n",
    "\n",
    "#Scaling in input variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "x=ss.fit_transform(x)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "KNN=KNeighborsClassifier(n_neighbors=10)\n",
    "LR=LogisticRegression()\n",
    "DT=DecisionTreeClassifier(random_state=20)\n",
    "GNB=GaussianNB()\n",
    "RF=RandomForestClassifier()\n",
    "\n",
    "models = []\n",
    "models.append(('KNeighborsClassifier', KNN))\n",
    "models.append(('LogisticRegression', LR))\n",
    "models.append(('DecisionTreeClassifier',DT))\n",
    "models.append(('GaussianNB', GNB))\n",
    "models.append(('RandomForestClassifier', RF))\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_curve,auc\n",
    "\n",
    "#Splitting the data into training and testing data\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20,random_state=42,stratify=y)\n",
    "\n",
    "Model=[]\n",
    "score=[]\n",
    "cvs=[]\n",
    "rocscore=[]\n",
    "for name,model in models:\n",
    "    print('****************************',name,'********************************')\n",
    "    print('\\n')\n",
    "    Model.append(name)\n",
    "    model.fit(x_train,y_train.values.ravel())\n",
    "    print(model)\n",
    "    pre=model.predict(x_test)\n",
    "    print('\\n')\n",
    "    AS=accuracy_score(y_test,pre)\n",
    "    print('Accuracy score = ', AS)\n",
    "    score.append(AS*100)\n",
    "    print('\\n')\n",
    "    sc=cross_val_score(model,x,y,cv=10,scoring='accuracy').mean()\n",
    "    print('Cross_val_Score = ', sc)\n",
    "    cvs.append(sc*100)\n",
    "    print('\\n')\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,pre)\n",
    "    roc_auc= auc(false_positive_rate, true_positive_rate)\n",
    "    print('roc_auc_score = ',roc_auc)\n",
    "    rocscore.append(roc_auc*100)\n",
    "    print('\\n')\n",
    "    print('classification_report\\n',classification_report(y_test,pre))\n",
    "    print('\\n')\n",
    "    cm=confusion_matrix(y_test,pre)\n",
    "    print(cm)\n",
    "    print('\\n')\n",
    "    plt.figure(figsize=(10,40))\n",
    "    plt.subplot(911)\n",
    "    plt.title(name)\n",
    "    print(sns.heatmap(cm,annot=True))\n",
    "    plt.subplot(912)\n",
    "    plt.title(name)\n",
    "    plt.plot(false_positive_rate, true_positive_rate, label = 'AUC= %0.2f'%roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    print('\\n\\n')\n",
    "    \n",
    "result=pd.DataFrame({'Model': Model, 'Accuracy_score': score, 'Cross_val_score':cvs, 'Roc_auc_curve':rocscore})\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
